import os
import streamlit as st
import pandas as pd
from langchain_google_vertexai import VertexAI, VertexAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
# --- ThÆ° viá»‡n má»›i cho Há»“i quy Tuyáº¿n tÃ­nh ---
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# --- Cáº¥u hÃ¬nh Vertex AI ---
PROJECT_ID = "vivid-pen-471404-t6"  # Thay tháº¿ báº±ng Project ID cá»§a báº¡n
LOCATION = "us-central1"

# Khá»Ÿi táº¡o Vertex AI
import vertexai

vertexai.init(project=PROJECT_ID, location=LOCATION)


# --- HÃ m xá»­ lÃ½ cho Chatbot (giá»¯ nguyÃªn) ---
@st.cache_resource
def create_conversational_chain(_vector_store):
    llm = VertexAI(model_name="gemini-2.5-flash", temperature=0.3)
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=_vector_store.as_retriever(),
        memory=memory
    )
    return chain


# --- HÃ m xá»­ lÃ½ cho Há»“i quy Tuyáº¿n tÃ­nh (giá»¯ nguyÃªn) ---
def perform_linear_regression(df, x_col, y_col):
    X = df[[x_col]].dropna()
    y = df[[y_col]].dropna()
    common_index = X.index.intersection(y.index)
    X = X.loc[common_index].values
    y = y.loc[common_index].values
    model = LinearRegression()
    model.fit(X, y)
    y_pred = model.predict(X)
    r2 = r2_score(y, y_pred)
    mse = mean_squared_error(y, y_pred)
    rmse = np.sqrt(mse)
    slope = model.coef_[0][0]
    intercept = model.intercept_[0]
    return {
        "model": model, "X": X, "y": y, "y_pred": y_pred,
        "r2": r2, "rmse": rmse, "slope": slope, "intercept": intercept
    }


# --- Giao diá»‡n ngÆ°á»i dÃ¹ng Streamlit ---
def main():
    st.set_page_config(page_title="ğŸ“ Trá»£ lÃ½ AI Äa nÄƒng", page_icon="ğŸ’¡")
    st.title("ğŸ’¡ Trá»£ lÃ½ AI Äa nÄƒng")

    tab1, tab2 = st.tabs(["ğŸ¤– Chatbot Há»i ÄÃ¡p PDF", "ğŸ“ˆ Há»“i quy Tuyáº¿n tÃ­nh"])

    # --- Giao diá»‡n Tab 1: Chatbot ---
    with tab1:
        st.header("Há»i Ä‘Ã¡p tÃ i liá»‡u PDF")
        st.write("Upload má»™t file PDF, sau Ä‘Ã³ Ä‘áº·t cÃ¢u há»i vá» ná»™i dung bÃªn trong.")

        uploaded_pdf = st.file_uploader("Chá»n file PDF cá»§a báº¡n", type="pdf", key="pdf_uploader")

        # <<< THAY Äá»”I QUAN TRá»ŒNG 1: Khá»Ÿi táº¡o táº¥t cáº£ cÃ¡c biáº¿n session_state cáº§n thiáº¿t
        if "conversation_chain" not in st.session_state:
            st.session_state.conversation_chain = None
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []
        if "processed_file_name" not in st.session_state:
            st.session_state.processed_file_name = None

        # <<< THAY Äá»”I QUAN TRá»ŒNG 2: Sá»­a Ä‘á»•i Ä‘iá»u kiá»‡n Ä‘á»ƒ chá»‰ xá»­ lÃ½ file má»›i
        if uploaded_pdf is not None and st.session_state.processed_file_name != uploaded_pdf.name:
            st.info(f"PhÃ¡t hiá»‡n file má»›i: '{uploaded_pdf.name}'. Báº¯t Ä‘áº§u xá»­ lÃ½...")
            with st.spinner("Äang xá»­ lÃ½ tÃ i liá»‡u PDF... ğŸ§ "):
                try:
                    with open(uploaded_pdf.name, "wb") as f:
                        f.write(uploaded_pdf.getbuffer())

                    loader = PyPDFLoader(uploaded_pdf.name)
                    documents = loader.load()
                    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
                    chunks = text_splitter.split_documents(documents)

                    embeddings = VertexAIEmbeddings(model_name="text-embedding-005")
                    vector_store = FAISS.from_documents(chunks, embedding=embeddings)

                    st.session_state.conversation_chain = create_conversational_chain(vector_store)
                    st.session_state.chat_history = []

                    # <<< THAY Äá»”I QUAN TRá»ŒNG 3: Ghi nhá»› tÃªn file Ä‘Ã£ xá»­ lÃ½
                    st.session_state.processed_file_name = uploaded_pdf.name

                    st.success("TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½! Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u há»i.")

                except Exception as e:
                    st.error(f"Lá»—i khi xá»­ lÃ½ file: {e}")
                finally:
                    os.remove(uploaded_pdf.name)

        # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Nháº­n input tá»« ngÆ°á»i dÃ¹ng
        user_question = st.chat_input("Äáº·t cÃ¢u há»i vá» ná»™i dung tÃ i liá»‡u...")

        if user_question:
            if st.session_state.conversation_chain:
                st.session_state.chat_history.append({"role": "user", "content": user_question})
                with st.chat_message("user"):
                    st.markdown(user_question)

                with st.spinner("Bot Ä‘ang suy nghÄ©... ğŸ¤”"):
                    response = st.session_state.conversation_chain({"question": user_question})
                    answer = response["chat_history"][-1].content
                    st.session_state.chat_history.append({"role": "assistant", "content": answer})
                    with st.chat_message("assistant"):
                        st.markdown(answer)
            else:
                st.warning("Vui lÃ²ng upload má»™t file PDF trÆ°á»›c.")

    # --- Giao diá»‡n Tab 2: Há»“i quy Tuyáº¿n tÃ­nh (giá»¯ nguyÃªn) ---
    with tab2:
        st.header("TÃ­nh toÃ¡n Há»“i quy Tuyáº¿n tÃ­nh")
        st.write("Upload má»™t file CSV chá»©a dá»¯ liá»‡u cá»§a báº¡n Ä‘á»ƒ báº¯t Ä‘áº§u.")
        uploaded_csv = st.file_uploader("Chá»n file CSV cá»§a báº¡n", type="csv", key="csv_uploader")

        if uploaded_csv is not None:
            df = pd.read_csv(uploaded_csv)
            st.write("**Xem trÆ°á»›c dá»¯ liá»‡u:**")
            st.dataframe(df.head())
            numeric_columns = df.select_dtypes(include=np.number).columns.tolist()
            if len(numeric_columns) < 2:
                st.warning("File CSV cáº§n Ã­t nháº¥t 2 cá»™t dá»¯ liá»‡u dáº¡ng sá»‘.")
            else:
                col1, col2 = st.columns(2)
                with col1:
                    x_axis = st.selectbox("Chá»n biáº¿n Ä‘á»™c láº­p (Trá»¥c X):", numeric_columns, index=0)
                with col2:
                    y_axis = st.selectbox("Chá»n biáº¿n phá»¥ thuá»™c (Trá»¥c Y):", numeric_columns, index=1)

                if st.button("Thá»±c hiá»‡n Há»“i quy"):
                    with st.spinner("Äang tÃ­nh toÃ¡n..."):
                        results = perform_linear_regression(df, x_axis, y_axis)
                        st.subheader("Káº¿t quáº£ Há»“i quy")
                        st.latex(f"y = {results['slope']:.4f}x + {results['intercept']:.4f}")
                        res_col1, res_col2 = st.columns(2)
                        with res_col1:
                            st.metric(label="R-squared (RÂ²)", value=f"{results['r2']:.4f}")
                        with res_col2:
                            st.metric(label="RMSE", value=f"{results['rmse']:.4f}")
                        st.subheader("Biá»ƒu Ä‘á»“ Trá»±c quan")
                        fig, ax = plt.subplots()
                        ax.scatter(results['X'], results['y'], alpha=0.7, label="Dá»¯ liá»‡u gá»‘c")
                        ax.plot(results['X'], results['y_pred'], color='red', linewidth=2, label="ÄÆ°á»ng há»“i quy")
                        ax.set_xlabel(x_axis)
                        ax.set_ylabel(y_axis)
                        ax.set_title(f"Há»“i quy tuyáº¿n tÃ­nh: {y_axis} vs {x_axis}")
                        ax.legend()
                        ax.grid(True)
                        st.pyplot(fig)


if __name__ == "__main__":
    main()